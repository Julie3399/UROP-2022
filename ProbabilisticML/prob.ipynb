{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Probabilistic Approach  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "tfd = tfp.distributions\n",
    "tfpl = tfp.layers\n",
    "\n",
    "from trainer import *\n",
    "# The experiment for tuning and searching can be found in the notebook:\n",
    "# https://colab.research.google.com/drive/1CXthH4dujMu475C-9G9FyLul6Ritrts1?usp=sharing\n",
    "# (the code has not been optimized for readability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fields like finance and medicine, it is often insufficient to provide a single point estimate of certain values: the desired estimations should come with a probability or confidence level, in order to answer questions like: \n",
    "- How sure are we to make this prediction? \n",
    "  \n",
    "- What is the probability that the actual value is higher than our estimate? \n",
    "  \n",
    "- What is the probability for the case where it is lower?    \n",
    "\n",
    "Therefore, it is natural to consider probabilistic machine learning techniques for tasks like these. Probabilistic methods allow us to take both **epistemic uncertainty** and **aleatoric uncertainty** into consideration, where epistemic uncertainty describes the uncertainty that are due to things one could in principle know but does not in practice (*e.g.* it is impossible to achieve zero measurement error) and aleatoric uncertainty refers to the data's inherent randomness (*e.g.* the data are generated from a random process).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>optionid</th>\n",
       "      <th>securityid</th>\n",
       "      <th>strike</th>\n",
       "      <th>callput</th>\n",
       "      <th>date_traded</th>\n",
       "      <th>contract_price</th>\n",
       "      <th>market_price</th>\n",
       "      <th>underlyings_price</th>\n",
       "      <th>contract_volume</th>\n",
       "      <th>days_to_maturity</th>\n",
       "      <th>moneyness</th>\n",
       "      <th>rate</th>\n",
       "      <th>volatility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42234</th>\n",
       "      <td>173731132.0</td>\n",
       "      <td>702263.0</td>\n",
       "      <td>19.3</td>\n",
       "      <td>C</td>\n",
       "      <td>2020-11-27</td>\n",
       "      <td>0.3100</td>\n",
       "      <td>0.31750</td>\n",
       "      <td>19.34225</td>\n",
       "      <td>227.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.002189</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>0.157719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50766</th>\n",
       "      <td>155396804.0</td>\n",
       "      <td>702263.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>C</td>\n",
       "      <td>2015-01-29</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.40375</td>\n",
       "      <td>15.69250</td>\n",
       "      <td>20.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.012419</td>\n",
       "      <td>0.002211</td>\n",
       "      <td>0.188274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17414</th>\n",
       "      <td>150256952.0</td>\n",
       "      <td>506534.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>C</td>\n",
       "      <td>2007-01-10</td>\n",
       "      <td>0.0730</td>\n",
       "      <td>0.07225</td>\n",
       "      <td>4.92130</td>\n",
       "      <td>38.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>0.911352</td>\n",
       "      <td>0.053485</td>\n",
       "      <td>0.129030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78002</th>\n",
       "      <td>161255597.0</td>\n",
       "      <td>702263.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>C</td>\n",
       "      <td>2017-08-02</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>0.10500</td>\n",
       "      <td>15.60225</td>\n",
       "      <td>556.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.975141</td>\n",
       "      <td>0.012943</td>\n",
       "      <td>0.126559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82738</th>\n",
       "      <td>161927336.0</td>\n",
       "      <td>702263.0</td>\n",
       "      <td>15.8</td>\n",
       "      <td>C</td>\n",
       "      <td>2017-07-20</td>\n",
       "      <td>0.3775</td>\n",
       "      <td>0.33375</td>\n",
       "      <td>15.96875</td>\n",
       "      <td>12.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.010680</td>\n",
       "      <td>0.012413</td>\n",
       "      <td>0.125298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          optionid  securityid  strike callput date_traded  contract_price  \\\n",
       "42234  173731132.0    702263.0    19.3       C  2020-11-27          0.3100   \n",
       "50766  155396804.0    702263.0    15.5       C  2015-01-29          0.3125   \n",
       "17414  150256952.0    506534.0     5.4       C  2007-01-10          0.0730   \n",
       "78002  161255597.0    702263.0    16.0       C  2017-08-02          0.1100   \n",
       "82738  161927336.0    702263.0    15.8       C  2017-07-20          0.3775   \n",
       "\n",
       "       market_price  underlyings_price  contract_volume  days_to_maturity  \\\n",
       "42234       0.31750           19.34225            227.0              21.0   \n",
       "50766       0.40375           15.69250             20.0              50.0   \n",
       "17414       0.07225            4.92130             38.0             254.0   \n",
       "78002       0.10500           15.60225            556.0              44.0   \n",
       "82738       0.33375           15.96875             12.0              29.0   \n",
       "\n",
       "       moneyness      rate  volatility  \n",
       "42234   1.002189  0.001333    0.157719  \n",
       "50766   1.012419  0.002211    0.188274  \n",
       "17414   0.911352  0.053485    0.129030  \n",
       "78002   0.975141  0.012943    0.126559  \n",
       "82738   1.010680  0.012413    0.125298  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_path = str(pathlib.Path(os.getcwd()).parent)\n",
    "viewData(parent_path).sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (85999, 6), val: (10750, 6), test: (10750, 6)\n"
     ]
    }
   ],
   "source": [
    "train_ds, valid_ds, test_ds = pipeline(parent_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Bayesian Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Introduction  \n",
    "\n",
    "A Bayesian Neural Network (BNN) is a network is stochastic weights, that is, the weights follow some probability distribution, say $p(\\theta)$ follows a normal distribution $N_{\\theta}(0, \\eta I)$ . Then we can define an observation model as \n",
    "\n",
    "$$\n",
    "p(t \\mid \\mathbf{x}, \\theta) = N_t(f_\\theta(\\mathbf{x}), \\sigma^2) \n",
    "$$  \n",
    "\n",
    "Then we can use Bayes' Rule to update the parameters  \n",
    "\n",
    "$$\n",
    "p(\\theta \\mid \\mathcal{D}) \\propto p(\\theta) \\prod_{i=1}^N p(t^{(i)} \\mid x^{(i)}, \\theta)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The marginal distribution is often intractable to compute, so we maximize the lower bound of the log likelihood instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 The Model  \n",
    "\n",
    "We use a Bayesian Neural Network with a hidden layer of `[300,100,100]`. The code for creating the model and training&evaluating are in the scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Remarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Mixture Density Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mixture Density Networks (MDN) [Bishop 1994](https://publications.aston.ac.uk/id/eprint/373/1/NCRG_94_004.pdf) learn the mixing coefficients and parameters for normal distirbutions and output the prediction as a sample drawn from a Gaussian Mixture. It is particularly useful when the distribution of data is multi-model, which is the case here.  \n",
    "\n",
    "More precisely, the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Ensemble of MDNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has not yet been implemented. The idea is that through the use of bagging, the different MDNs can learn the different modals in the data, thus they can be used together to give a better estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A not so surprisingly common problem with BNNs is underfitting: the use of isotropic normal distributions are not sufficient to model high dimensional, high complexity true posteriors. To solve this issue, many approaches have been proposed, for instance a new posterior (ref. ) and a heavy tailed prior. \n",
    "\n",
    "These topics will be explored further."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('my')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ae074981885b87eddeb2f9c2c772d0c6068182876a016d28b3a0c777d45839f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
