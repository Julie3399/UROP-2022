{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "from hyperopt import tpe, STATUS_OK, Trials, hp, fmin, STATUS_OK, space_eval\n",
    "\n",
    "from preprocess import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 Support Vector Regression (SVR) algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a data set $D=\\left\\{x_i, y_i\\right\\}_{i=1}^n$ of $N$ points, the method of $\\varepsilon$-Support Vector Regression(denoted SVR) fits a function $f$ to the data $D$ of the following form:  \n",
    "\n",
    "\n",
    "$$\n",
    "f(x)=w^T \\phi(x)+b\n",
    "$$\n",
    "\n",
    "\n",
    "We aim to minimize\n",
    "$$\n",
    "J(w)=\\frac{1}{2}||w||^2+C \\sum_{i=1}^n\\left|\\xi_i\\right|\n",
    "$$\n",
    "subject to constrains\n",
    "$$\n",
    "\\left|y_i-w_i \\phi(x_i)\\right| \\leq \\varepsilon+\\left|\\xi_i\\right|\n",
    "$$  \n",
    "\n",
    "\n",
    "where:\n",
    "\n",
    "-   $w, b$ are coefficients to be estimated    \n",
    "\n",
    "-   $\\phi(\\mathbf{x})$ is a mapping from lower dimensional $x$-space to higer dimensional feature space  \n",
    "\n",
    "-   $\\xi_i$ is a slack variable of the point $x_i$ for dealing with infeasible constraints, for any data point $(x_i, y_i)$ that falls outside of $\\varepsilon$, its deviation from the margin is denoted as $\\xi_i$   \n",
    "\n",
    "- $\\varepsilon$ : distance from margins to hyperplane, only data points with absolute error less than or equal to $\\varepsilon+\\left|\\xi_i\\right|$ will be considered\n",
    " \n",
    "-   $C$ is a positive constant that controls the penalty imposed on observations that lie outside the margin specified $\\epsilon$, as $C$ increases, the tolerence for points outside margins increases \n",
    "\n",
    "One great advantage of SVMs is that solving for the optimal parameters is equivalent to a convex optimization problem, in which case all local optimum are also global.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data from `data.csv`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>optionid</th>\n",
       "      <th>securityid</th>\n",
       "      <th>strike</th>\n",
       "      <th>callput</th>\n",
       "      <th>date_traded</th>\n",
       "      <th>contract_price</th>\n",
       "      <th>market_price</th>\n",
       "      <th>underlyings_price</th>\n",
       "      <th>contract_volume</th>\n",
       "      <th>days_to_maturity</th>\n",
       "      <th>moneyness</th>\n",
       "      <th>rate</th>\n",
       "      <th>volatility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>150034236.0</td>\n",
       "      <td>504569.0</td>\n",
       "      <td>0.42</td>\n",
       "      <td>C</td>\n",
       "      <td>2006-10-18</td>\n",
       "      <td>0.0715</td>\n",
       "      <td>0.07025</td>\n",
       "      <td>0.488500</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.163095</td>\n",
       "      <td>0.053646</td>\n",
       "      <td>0.022956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>150247468.0</td>\n",
       "      <td>504880.0</td>\n",
       "      <td>40.00</td>\n",
       "      <td>C</td>\n",
       "      <td>2006-10-18</td>\n",
       "      <td>0.1240</td>\n",
       "      <td>0.12250</td>\n",
       "      <td>39.913799</td>\n",
       "      <td>56137.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.997845</td>\n",
       "      <td>0.053646</td>\n",
       "      <td>0.114784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>150255000.0</td>\n",
       "      <td>506496.0</td>\n",
       "      <td>62.00</td>\n",
       "      <td>C</td>\n",
       "      <td>2006-10-18</td>\n",
       "      <td>0.1720</td>\n",
       "      <td>0.17400</td>\n",
       "      <td>61.827798</td>\n",
       "      <td>27369.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.997223</td>\n",
       "      <td>0.053646</td>\n",
       "      <td>0.106823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>150255496.0</td>\n",
       "      <td>506497.0</td>\n",
       "      <td>53.50</td>\n",
       "      <td>C</td>\n",
       "      <td>2006-10-18</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>0.26550</td>\n",
       "      <td>53.612900</td>\n",
       "      <td>1224.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.002110</td>\n",
       "      <td>0.053646</td>\n",
       "      <td>0.110336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>150255498.0</td>\n",
       "      <td>506497.0</td>\n",
       "      <td>54.00</td>\n",
       "      <td>C</td>\n",
       "      <td>2006-10-18</td>\n",
       "      <td>0.0750</td>\n",
       "      <td>0.06450</td>\n",
       "      <td>53.612900</td>\n",
       "      <td>963.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.992831</td>\n",
       "      <td>0.053646</td>\n",
       "      <td>0.110336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     optionid  securityid  strike callput date_traded  \\\n",
       "0           0  150034236.0    504569.0    0.42       C  2006-10-18   \n",
       "1           1  150247468.0    504880.0   40.00       C  2006-10-18   \n",
       "2           2  150255000.0    506496.0   62.00       C  2006-10-18   \n",
       "3           3  150255496.0    506497.0   53.50       C  2006-10-18   \n",
       "4           4  150255498.0    506497.0   54.00       C  2006-10-18   \n",
       "\n",
       "   contract_price  market_price  underlyings_price  contract_volume  \\\n",
       "0          0.0715       0.07025           0.488500              5.0   \n",
       "1          0.1240       0.12250          39.913799          56137.0   \n",
       "2          0.1720       0.17400          61.827798          27369.0   \n",
       "3          0.2960       0.26550          53.612900           1224.0   \n",
       "4          0.0750       0.06450          53.612900            963.0   \n",
       "\n",
       "   days_to_maturity  moneyness      rate  volatility  \n",
       "0               2.0   1.163095  0.053646    0.022956  \n",
       "1               2.0   0.997845  0.053646    0.114784  \n",
       "2               2.0   0.997223  0.053646    0.106823  \n",
       "3               2.0   1.002110  0.053646    0.110336  \n",
       "4               2.0   0.992831  0.053646    0.110336  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_path = str(pathlib.Path(os.getcwd()).parent)\n",
    "df = pd.read_csv(os.path.join(parent_path, 'data/data.csv'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`dataframe_BS` contains all data from `df`, which is used to train the SVR model.\n",
    "\n",
    "`small_dataframe_BS` contains 20% of the data from `df`, which is used to perform hyperparamter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_BS = makeBS(df)\n",
    "\n",
    "small_ds = df.sample(frac=0.2, random_state=42)\n",
    "small_dataframe_BS = makeBS(small_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get train and test data in tuples of features and targets. Print out their dimensions to check they are in shapes we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85999, 5) (85999,) (21500, 5) (21500,)\n",
      "(17200, 5) (17200,) (4300, 5) (4300,)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train) , (x_test, y_test)= propocessed(dataframe_BS)\n",
    "print(np.shape(x_train), np.shape(y_train), np.shape(x_test), np.shape(y_test))\n",
    "(small_x_train, small_y_train) , (small_x_test, small_y_test)= propocessed(small_dataframe_BS)\n",
    "print(np.shape(small_x_train), np.shape(small_y_train), np.shape(small_x_test), np.shape(small_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this approach, we use the radial basis function (RBF) as a transformation kernel for our data.    \n",
    "\n",
    "For a pair of data points $x_i, x_j$, the RBF is defined as  \n",
    "\n",
    "$$\n",
    "k(x_i, x_j) = \\exp(-\\gamma ||x_i-x_j||)\n",
    "$$  \n",
    "\n",
    "where $\\gamma$ is a positive hyperparameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = SVR(kernel = 'rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVR()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVR</label><div class=\"sk-toggleable__content\"><pre>SVR()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVR()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model using RMSE (root mean square error):\n",
    "$$\n",
    "R M S E=\\sqrt{\\frac{1}{N} \\sum_{i=1}^N\\left(y_i-\\hat{y}_i\\right)^2}\n",
    "$$\n",
    "- $y_i$: true value\n",
    "- $\\hat{y}_i$: predicted value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09518605318842471"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = regressor.predict(x_test)\n",
    "rmse = np.sqrt(np.mean((y_test-y_pred)**2))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Tuning hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ranges of hyperparameter are chosen based on experiments in [Practical Option Pricing with\n",
    "Support Vector Regression and MART\n",
    "by\n",
    "Ian I-En Choo\n",
    "Stanford University](http://cs229.stanford.edu/proj2009/Choo.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The list of values for C are [  10.  100. 1000.]\n",
      "The list of values for epsilon are [0.1   0.01  0.001]\n",
      "The list of values for gamma are [1.e-05 1.e-04 1.e-03 1.e-02]\n"
     ]
    }
   ],
   "source": [
    "C_range = np.logspace(1,3,3)\n",
    "print(f'The list of values for C are {C_range}')\n",
    "\n",
    "epsilon_range = np.logspace(-1,-3,3)\n",
    "print(f'The list of values for epsilon are {epsilon_range}')\n",
    "\n",
    "gamma_range = np.logspace(-5, -2, 4)\n",
    "print(f'The list of values for gamma are {gamma_range}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { \n",
    "    # Regularization parameter\n",
    "    \"C\": C_range,\n",
    "    # Kernel type\n",
    "    \"kernel\": ['rbf'],\n",
    "    # margin parameter\n",
    "    \"epsilon\":epsilon_range,\n",
    "    # Gamma is the Kernel coefficient for ‘rbf’, ‘poly’ and ‘sigmoid’\n",
    "    \"gamma\": gamma_range.tolist()+['scale', 'auto']\n",
    "    }\n",
    "\n",
    "# Set up score\n",
    "scoring = ['neg_mean_squared_error']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning Using Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method is much more time-consuming than random search, but achieving similar results, therefore we use the latter instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Define grid search\n",
    "grid_search = GridSearchCV(estimator=regressor, \n",
    "                           param_grid=param_grid, \n",
    "                           scoring=scoring, \n",
    "                           refit='neg_root_mean_squared_error', \n",
    "                           n_jobs=-1,\n",
    "                           cv = 3,\n",
    "                           verbose=2)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Fit grid search\n",
    "grid_result = grid_search.fit(small_x_train, small_y_train)\n",
    "# Print grid search summary\n",
    "grid_result\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Print the best accuracy score for the training dataset\n",
    "print(f'The best accuracy score for the training dataset is {grid_result.best_score_:.4f}')\n",
    "# Print the hyperparameters for the best score\n",
    "print(f'The best hyperparameters are {grid_result.best_params_}')\n",
    "# Print the best accuracy score for the testing dataset\n",
    "print(f'The accuracy score for the testing dataset is {grid_search.score(x_test, y_test):.4f}')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"best_regressor = grid_result.best_estimator_\n",
    "y_pred = best_regressor.predict(x_test)\n",
    "rmse = np.sqrt(np.mean((y_test-y_pred)**2))\n",
    "rmse\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning Using Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3, estimator=SVR(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;C&#x27;: array([  10.,  100., 1000.]),\n",
       "                                        &#x27;epsilon&#x27;: array([0.1  , 0.01 , 0.001]),\n",
       "                                        &#x27;gamma&#x27;: [1e-05, 0.0001, 0.001, 0.01,\n",
       "                                                  &#x27;scale&#x27;, &#x27;auto&#x27;],\n",
       "                                        &#x27;kernel&#x27;: [&#x27;rbf&#x27;]},\n",
       "                   refit=&#x27;neg_mean_squared_error&#x27;,\n",
       "                   scoring=[&#x27;neg_mean_squared_error&#x27;], verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3, estimator=SVR(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;C&#x27;: array([  10.,  100., 1000.]),\n",
       "                                        &#x27;epsilon&#x27;: array([0.1  , 0.01 , 0.001]),\n",
       "                                        &#x27;gamma&#x27;: [1e-05, 0.0001, 0.001, 0.01,\n",
       "                                                  &#x27;scale&#x27;, &#x27;auto&#x27;],\n",
       "                                        &#x27;kernel&#x27;: [&#x27;rbf&#x27;]},\n",
       "                   refit=&#x27;neg_mean_squared_error&#x27;,\n",
       "                   scoring=[&#x27;neg_mean_squared_error&#x27;], verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVR</label><div class=\"sk-toggleable__content\"><pre>SVR()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVR</label><div class=\"sk-toggleable__content\"><pre>SVR()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=SVR(), n_jobs=-1,\n",
       "                   param_distributions={'C': array([  10.,  100., 1000.]),\n",
       "                                        'epsilon': array([0.1  , 0.01 , 0.001]),\n",
       "                                        'gamma': [1e-05, 0.0001, 0.001, 0.01,\n",
       "                                                  'scale', 'auto'],\n",
       "                                        'kernel': ['rbf']},\n",
       "                   refit='neg_mean_squared_error',\n",
       "                   scoring=['neg_mean_squared_error'], verbose=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define random search\n",
    "random_search = RandomizedSearchCV(estimator=regressor, \n",
    "                           param_distributions=param_grid, \n",
    "                           scoring=scoring, \n",
    "                           refit='neg_mean_squared_error', \n",
    "                           n_jobs=-1, \n",
    "                           cv=3, \n",
    "                           verbose=1)\n",
    "# Fit grid search\n",
    "random_result = random_search.fit(small_x_train, small_y_train)\n",
    "# Print grid search summary\n",
    "random_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hyperparameters are {'kernel': 'rbf', 'gamma': 0.01, 'epsilon': 0.1, 'C': 1000.0}\n"
     ]
    }
   ],
   "source": [
    "# Print the hyperparameters for the best score\n",
    "print(f'The best hyperparameters are {random_result.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09394793684421912"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_regressor = random_result.best_estimator_\n",
    "y_pred = best_regressor.predict(x_test)\n",
    "rmse = np.sqrt(np.mean((y_test-y_pred)**2))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning Using Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [20:02<00:00, 24.05s/trial, best loss: 0.004125688799182951] \n"
     ]
    }
   ],
   "source": [
    "# Space\n",
    "space = {\n",
    "    'C' : hp.choice('C', C_range),\n",
    "    'epsilon':hp.choice('epsilon', epsilon_range),\n",
    "    'gamma' : hp.choice('gamma', gamma_range.tolist()+['scale', 'auto']),\n",
    "    'kernel' : hp.choice('kernel', ['rbf', 'poly'])\n",
    "}\n",
    "\n",
    "# Objective function\n",
    "def objective(params):\n",
    "    \n",
    "    svr = SVR(**params)\n",
    "    scores = cross_val_score(svr, small_x_train, small_y_train, cv=3, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    # Extract the best score\n",
    "    best_score = max(scores)\n",
    "    # Loss must be minimized\n",
    "    loss = - best_score\n",
    "    # Dictionary with information for evaluation\n",
    "    return {'loss': loss, 'params': params, 'status': STATUS_OK}\n",
    "\n",
    "# Trials to track progress\n",
    "bayes_trials = Trials()\n",
    "\n",
    "# Optimize\n",
    "best = fmin(fn = objective, space = space, algo = tpe.suggest, max_evals = 50, trials = bayes_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 2, 'epsilon': 2, 'gamma': 4, 'kernel': 0}\n",
      "{'C': 1000.0, 'epsilon': 0.001, 'gamma': 'scale', 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# Print the index of the best parameters\n",
    "print(best)\n",
    "# Print the values of the best parameters\n",
    "print(space_eval(space, best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model using the best parameters\n",
    "svc_bo = SVR(C=space_eval(space, best)['C'], gamma=space_eval(space, best)['gamma'], kernel=space_eval(space, best)['kernel']).fit(small_x_train, small_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07707476526906"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = svc_bo.predict(x_test)\n",
    "rmse = np.sqrt(np.mean((y_test-y_pred)**2))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of Hyperparameter Tuning using Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f265f4830d5af5b2ae9e939ec8f9421eeb4f9df757731f4577dcb81e0b15c08"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
