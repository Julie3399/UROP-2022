{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from models import *\n",
    "from trainer import *\n",
    "from preprocess import *\n",
    "from callbacks import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_path = str(pathlib.Path(os.getcwd()).parent)\n",
    "df = pd.read_csv(os.path.join(parent_path, 'data/processed_data.csv'))\n",
    "df = df.drop(['Unnamed: 0', 'Unnamed: 0.1', 'optionid', 'securityid'], axis=1)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the first neueral network that uses the same set of inputs as the Black-Scholes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_BS = np.vstack((df['strike'].values,\n",
    "                      df['asset_price'].values,\n",
    "                      df['days_to_maturity'].values,\n",
    "                      df['volatility'].values,\n",
    "                      df['rate'].values,\n",
    "                      df['contract_price'].values)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, valid_ds, test_ds = getDatasets(dataframe_BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = shuffle_and_batch_dataset(train_ds, batch_size=32)\n",
    "valid_ds = shuffle_and_batch_dataset(valid_ds, batch_size=32)\n",
    "test_ds = shuffle_and_batch_dataset(test_ds, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = map_dataset(train_ds, xy_split)\n",
    "valid_ds = map_dataset(valid_ds, xy_split)\n",
    "test_ds = map_dataset(test_ds, xy_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "valid_ds = valid_ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "test_ds = test_ds.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Start training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_num_epochs = 5 # print progress every print_num_epochs epochs\n",
    "\n",
    "path_to_save = os.path.join(parent_path, 'NeuralNetwork/models/')  # path to save the model\n",
    "\n",
    "patience = 10  \n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "loss = tf.keras.losses.MeanAbsoluteError(name='loss')\n",
    "\n",
    "metrics = tf.keras.metrics.MeanAbsolutePercentageError(name='accuracy')\n",
    "\n",
    "num_epochs = 10  \n",
    "\n",
    "model = getModel(input_shape = (5, ),\n",
    "                 hidden_units = [14, 14, 14],\n",
    "                 output_shape = (1, ),\n",
    "                 batchnorm = True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some callbacks  \n",
    "ckpt = CheckpointCallback(path_to_save)\n",
    "printing =PrintProgress(num_epochs=print_num_epochs)\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(patience=patience, monitor='val_loss')\n",
    "callbacks = [ckpt, printing, early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = compile_and_fit(model,\n",
    "                          optimizer,\n",
    "                          loss,\n",
    "                          num_epochs,\n",
    "                          train_ds,\n",
    "                          valid_ds,\n",
    "                          metrics,\n",
    "                          callbacks\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "214ae085943121352a1c46be52870768915bb1800a79b1ca0ca08a53dfbff110"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
